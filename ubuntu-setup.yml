---
- name: Setup Ubuntu 24 System
  hosts: localhost
  connection: local
  become: yes

  vars:
    ssh_port: 33412
    ssh_user: "{{ ansible_env.SUDO_USER | default(ansible_env.USER) }}"
    user_home: "{{ '/home/' + (ansible_env.SUDO_USER | default(ansible_env.USER)) }}"
    auto_reboot_time: "06:00"  # 6 AM daily reboot

    # Local installer storage for reproducible builds
    installers_base_path: "/opt/installers"

    # NVIDIA Driver configuration
    nvidia_driver_version: "580"
    nvidia_driver_version_full: "580.95.05"
    nvidia_driver_local_repo_url: "https://developer.download.nvidia.com/compute/nvidia-driver/{{ nvidia_driver_version_full }}/local_installers/nvidia-driver-local-repo-ubuntu2404-{{ nvidia_driver_version_full }}_1.0-1_amd64.deb"

    # CUDA Toolkit configuration
    cuda_version: "13-0"
    cuda_version_full: "13.0"
    cuda_version_full_numeric: "13.0.2"
    cuda_local_repo_url: "https://developer.download.nvidia.com/compute/cuda/{{ cuda_version_full_numeric }}/local_installers/cuda-repo-ubuntu2404-13-0-local_{{ cuda_version_full_numeric }}-580.95.05-1_amd64.deb"

    # TensorRT version configuration
    tensorrt_version_major: "10.13"     # Major version (e.g., "10.13")
    tensorrt_version_full: "10.13.3"    # Full version including point release (e.g., "10.13.3")
    tensorrt_version_pattern: "10.13.*" # Pattern for apt search

    # TensorRT installation method:
    # - "local": Download and use local repository (recommended - guarantees version availability)
    # - "network": Use CUDA network repository (only works while version available)
    # - "auto": Try network first, fall back to local if not found
    tensorrt_install_method: "local"

    # TensorRT local repo URL (auto-constructed if using local method)
    # Override this if you want to use a custom URL or local file path
    tensorrt_local_repo_url: ""
    realvnc_version: "7.13.0"
    
    log_file: "/var/log/ansible-ubuntu-setup-{{ ansible_date_time.iso8601_basic_short }}.log"

  tasks:

    # ==========================================================
    # 0. PROMPT FOR HEALTHCHECKS URL
    # ==========================================================
    - name: Prompt for Healthchecks.io URL
      pause:
        prompt: |

          ============================================================
          HEALTHCHECKS.IO SETUP
          ============================================================

          Please create a healthcheck at https://healthchecks.io

          Steps:
          1. Go to https://healthchecks.io and create a free account
          2. Create a new check with name: "{{ ansible_hostname }}"
          3. Set the period to 10 minutes (allows 5 min pings + buffer)
          4. Copy the ping URL (looks like: https://hc-ping.com/YOUR-UUID-HERE)

          Paste your Healthchecks.io ping URL (or press Enter to skip)
      register: healthchecks_prompt
      when: healthchecks_url is not defined

    - name: Set healthchecks URL from user input or default
      set_fact:
        healthchecks_url: "{{ healthchecks_prompt.user_input if (healthchecks_prompt.user_input | default('') | length > 0) else 'SKIPPED' }}"
      when: healthchecks_url is not defined

    - name: Set healthchecks URL if already defined
      set_fact:
        healthchecks_url: "{{ healthchecks_url }}"
      when: healthchecks_url is defined

    # ==========================================================
    # 1. INITIALIZE LOG FILE
    # ==========================================================
    - name: Create log directory
      file:
        path: /var/log
        state: directory
        mode: '0755'
    
    - name: Initialize log file with header
      copy:
        dest: "{{ log_file }}"
        content: |
          ===================================================================
          Ubuntu 24 System Setup - Started at {{ ansible_date_time.iso8601 }}
          Host: {{ inventory_hostname }}
          ===================================================================

        mode: '0644'
      tags: always

    # ==========================================================
    # 1. PRE-FLIGHT VALIDATION
    # ==========================================================
    - name: Check available disk space on /opt
      shell: df -BG /opt | tail -1 | awk '{print $4}' | sed 's/G//'
      register: opt_free_space
      changed_when: false
      failed_when: false

    - name: Fail if insufficient disk space
      fail:
        msg: "Insufficient disk space on /opt. Available: {{ opt_free_space.stdout }}GB, Required: 5GB minimum for installers"
      when: opt_free_space.stdout | int < 5

    - name: Test network connectivity to NVIDIA
      uri:
        url: "https://developer.download.nvidia.com/"
        method: HEAD
        timeout: 10
        status_code: [200, 301, 302, 403]
      register: nvidia_network_check
      failed_when: false
      changed_when: false

    - name: Test network connectivity to CUDA repos
      uri:
        url: "https://developer.download.nvidia.com/compute/cuda/"
        method: HEAD
        timeout: 10
        status_code: [200, 301, 302, 403]
      register: cuda_network_check
      failed_when: false
      changed_when: false

    - name: Log pre-flight validation
      shell: |
        echo "===========================================================" >> {{ log_file }}
        echo "1. PRE-FLIGHT VALIDATION - {{ ansible_date_time.iso8601 }}" >> {{ log_file }}
        echo "===========================================================" >> {{ log_file }}
        echo "Available disk space on /opt: {{ opt_free_space.stdout }}GB" >> {{ log_file }}
        echo "Network connectivity to NVIDIA: {{ 'OK' if nvidia_network_check.status is defined else 'FAILED (offline mode?)' }}" >> {{ log_file }}
        echo "Network connectivity to CUDA repos: {{ 'OK' if cuda_network_check.status is defined else 'FAILED (offline mode?)' }}" >> {{ log_file }}
        echo "" >> {{ log_file }}

    - debug:
        msg: "âœ… Pre-flight checks passed: {{ opt_free_space.stdout }}GB available, network: {{ 'online' if nvidia_network_check.status is defined else 'offline' }}"

    # ==========================================================
    # 2. CREATE LOCAL INSTALLER STORAGE
    # ==========================================================
    - name: Create local installer base directory
      file:
        path: "{{ installers_base_path }}"
        state: directory
        mode: '0755'
        owner: root
        group: root

    - name: Create nvidia-driver installer directory
      file:
        path: "{{ installers_base_path }}/nvidia-driver"
        state: directory
        mode: '0755'

    - name: Create cuda installer directory
      file:
        path: "{{ installers_base_path }}/cuda"
        state: directory
        mode: '0755'

    - name: Create tensorrt installer directory
      file:
        path: "{{ installers_base_path }}/tensorrt"
        state: directory
        mode: '0755'

    - name: Log local installer storage creation
      shell: |
        echo "===========================================================" >> {{ log_file }}
        echo "2. LOCAL INSTALLER STORAGE - {{ ansible_date_time.iso8601 }}" >> {{ log_file }}
        echo "===========================================================" >> {{ log_file }}
        echo "Created {{ installers_base_path }} for reproducible builds" >> {{ log_file }}
        echo "" >> {{ log_file }}

    - name: Create version manifest
      copy:
        dest: "{{ installers_base_path }}/VERSIONS.json"
        mode: '0644'
        content: |
          {
            "manifest_created": "{{ ansible_date_time.iso8601 }}",
            "hostname": "{{ ansible_hostname }}",
            "ubuntu_version": "{{ ansible_distribution_version }}",
            "components": {
              "nvidia_driver": {
                "version": "{{ nvidia_driver_version_full }}",
                "method": "local_repository",
                "url": "{{ nvidia_driver_local_repo_url }}"
              },
              "cuda_toolkit": {
                "version": "{{ cuda_version_full_numeric }}",
                "method": "local_repository",
                "url": "{{ cuda_local_repo_url }}"
              },
              "tensorrt": {
                "version": "{{ tensorrt_version_full }}",
                "method": "{{ tensorrt_install_method }}",
                "url": "{{ tensorrt_local_repo_url if tensorrt_local_repo_url else 'auto-constructed' }}"
              },
              "pytorch_cuda": {
                "version": "cu130",
                "note": "Installed via pip in post-reboot-verify.yml"
              }
            },
            "reproducibility": {
              "local_installers": "{{ installers_base_path }}",
              "package_holding": "dpkg hold on nvidia-*-{{ nvidia_driver_version }}, cuda-*-{{ cuda_version }}, tensorrt-*",
              "unattended_upgrades_blacklist": "/etc/apt/apt.conf.d/51nvidia-blacklist",
              "apt_preferences": "/etc/apt/preferences.d/99-gpu-stack-pinning"
            }
          }

    - debug:
        msg: "ðŸ“‹ Version manifest created at {{ installers_base_path }}/VERSIONS.json"

    - name: Create SHA-256 checksums placeholder file
      copy:
        dest: "{{ installers_base_path }}/SHA256SUMS"
        mode: '0644'
        content: |
          # SHA-256 Checksums for GPU Stack Installers
          # Generated: {{ ansible_date_time.iso8601 }}
          # Verify with: cd /opt/installers && sha256sum -c SHA256SUMS
          #
          # Checksums will be appended during installation
        force: no

    # ==========================================================
    # 3. SYSTEM UPDATE
    # ==========================================================
    - name: Update apt cache and upgrade packages
      apt:
        update_cache: yes
        cache_valid_time: 3600
        upgrade: dist
      register: apt_upgrade
    
    - name: Log system update
      shell: |
        echo "===========================================================" >> {{ log_file }}
        echo "1. SYSTEM UPDATE - $(date)" >> {{ log_file }}
        echo "===========================================================" >> {{ log_file }}
        echo "âœ… System updated successfully." >> {{ log_file }}
        echo "" >> {{ log_file }}
    
    - debug: msg="âœ… System updated successfully."

    # ==========================================================
    # 2. COMMON UTILITIES & MONITORING TOOLS
    # ==========================================================
    - name: Install general developer and monitoring tools
      apt:
        name:
          - build-essential
          - git
          - cmake
          - unzip
          - zip
          - wget
          - curl
          - vim
          - nano
          - tree
          - jq
          - netcat-traditional
          - psmisc
          - htop
          - btop
          - bmon
          - iftop
          - nvtop
          - wavemon
          - net-tools
          - lm-sensors
          - speedtest-cli
        state: present
      register: tools_install
    
    - name: Print versions of installed core tools
      shell: |
        echo "htop: $(htop --version | head -n1)"
        echo "git: $(git --version)"
        echo "cmake: $(cmake --version | head -n1)"
      register: base_versions
    
    - name: Log tools installation
      shell: |
        echo "===========================================================" >> {{ log_file }}
        echo "2. COMMON UTILITIES & MONITORING TOOLS - $(date)" >> {{ log_file }}
        echo "===========================================================" >> {{ log_file }}
        {{ base_versions.stdout_lines | map('regex_replace', '^', 'echo "') | map('regex_replace', '$', '" >> {{ log_file }}') | join('\n') }}
        echo "" >> {{ log_file }}
    
    - debug: msg="{{ base_versions.stdout_lines }}"

    # ==========================================================
    # 3. SSH CONFIGURATION
    # ==========================================================
    - name: Install and configure OpenSSH server
      apt: { name: openssh-server, state: present }

    - name: Configure SSH port and authentication
      blockinfile:
        path: /etc/ssh/sshd_config
        marker: "# {mark} ANSIBLE MANAGED BLOCK"
        block: |
          Port {{ ssh_port }}
          PasswordAuthentication yes
          PubkeyAuthentication yes
          PermitRootLogin no
        validate: '/usr/sbin/sshd -t -f %s'
      notify: restart sshd
      register: ssh_config
    
    - name: Log SSH configuration
      shell: |
        echo "===========================================================" >> {{ log_file }}
        echo "3. SSH CONFIGURATION - $(date)" >> {{ log_file }}
        echo "===========================================================" >> {{ log_file }}
        echo "âœ… SSH configured on port {{ ssh_port }}" >> {{ log_file }}
        echo "" >> {{ log_file }}
    
    - debug: msg="âœ… SSH configured on port {{ ssh_port }}"

    # ==========================================================
    # 4. FIREWALL
    # ==========================================================
    - name: Install and enable UFW
      apt: { name: ufw, state: present }
    - name: Allow SSH through UFW
      ufw: { rule: allow, port: "{{ ssh_port }}", proto: tcp }
    - name: Enable UFW non-interactively
      command: ufw --force enable
      args: { creates: /etc/ufw/ufw.conf }
      register: ufw_enable
    
    - name: Log firewall configuration
      shell: |
        echo "===========================================================" >> {{ log_file }}
        echo "4. FIREWALL - $(date)" >> {{ log_file }}
        echo "===========================================================" >> {{ log_file }}
        echo "âœ… UFW enabled with SSH port {{ ssh_port }} open." >> {{ log_file }}
        echo "" >> {{ log_file }}
    
    - debug: msg="âœ… UFW enabled with SSH port {{ ssh_port }} open."

    # ==========================================================
    # 5. AUTO-REBOOT SYSTEMD TIMER
    # ==========================================================
    - name: Create daily reboot service
      copy:
        dest: /etc/systemd/system/daily-reboot.service
        mode: '0644'
        content: |
          [Unit]
          Description=Daily System Reboot

          [Service]
          Type=oneshot
          ExecStart=/usr/sbin/shutdown -r now

    - name: Create daily reboot timer
      copy:
        dest: /etc/systemd/system/daily-reboot.timer
        mode: '0644'
        content: |
          [Unit]
          Description=Daily System Reboot Timer

          [Timer]
          OnCalendar=*-*-* {{ auto_reboot_time }}:00
          Persistent=true

          [Install]
          WantedBy=timers.target
      notify: reload systemd

    - name: Enable daily reboot timer
      systemd: { name: daily-reboot.timer, enabled: yes, state: started, daemon_reload: yes }
      register: reboot_timer
    
    - name: Log auto-reboot configuration
      shell: |
        echo "===========================================================" >> {{ log_file }}
        echo "5. AUTO-REBOOT SYSTEMD TIMER - $(date)" >> {{ log_file }}
        echo "===========================================================" >> {{ log_file }}
        echo "âœ… Daily reboot timer active ({{ auto_reboot_time }})" >> {{ log_file }}
        echo "" >> {{ log_file }}
    
    - debug: msg="âœ… Daily reboot timer active ({{ auto_reboot_time }})"

    # ==========================================================
    # 6. TAILSCALE
    # ==========================================================
    - name: Setup Tailscale repository and install
      block:
        - name: Create keyrings directory for Tailscale
          file:
            path: /usr/share/keyrings
            state: directory
            mode: '0755'

        - name: Download Tailscale GPG key
          get_url:
            url: https://pkgs.tailscale.com/stable/ubuntu/noble.noarmor.gpg
            dest: /usr/share/keyrings/tailscale-archive-keyring.gpg
            mode: '0644'

        - name: Download Tailscale repository list
          get_url:
            url: https://pkgs.tailscale.com/stable/ubuntu/noble.tailscale-keyring.list
            dest: /etc/apt/sources.list.d/tailscale.list
            mode: '0644'

        - name: Update apt cache for Tailscale
          apt:
            update_cache: yes

        - name: Install Tailscale
          apt:
            name: tailscale
            state: present

        - name: Enable and start tailscaled service
          systemd:
            name: tailscaled
            enabled: yes
            state: started

        - shell: echo "âœ… Tailscale installed. Run 'sudo tailscale up' to authenticate." >> {{ log_file }}
      rescue:
        - debug: msg="âš ï¸ Tailscale repo or install failed."
        - shell: echo "âš ï¸ Tailscale repo or install failed." >> {{ log_file }}
    
    - name: Log Tailscale installation
      shell: |
        echo "===========================================================" >> {{ log_file }}
        echo "6. TAILSCALE - $(date)" >> {{ log_file }}
        echo "===========================================================" >> {{ log_file }}
    
    - debug: msg="âœ… Tailscale installed. Run 'sudo tailscale up' to authenticate."

    # ==========================================================
    # 7. REALVNC SERVER
    # ==========================================================
    - name: Install RealVNC
      block:
        - get_url:
            url: "https://downloads.realvnc.com/download/file/vnc.files/VNC-Server-{{ realvnc_version }}-Linux-x64.deb"
            dest: /tmp/realvnc-server.deb
            timeout: 60
        - apt: { deb: /tmp/realvnc-server.deb }
        - shell: echo "âœ… RealVNC {{ realvnc_version }} installed." >> {{ log_file }}
        - debug: msg="âœ… RealVNC {{ realvnc_version }} installed."
      rescue:
        - debug: msg="âš ï¸ RealVNC download failed."
        - shell: echo "âš ï¸ RealVNC download failed." >> {{ log_file }}
    
    - name: Log RealVNC installation
      shell: |
        echo "===========================================================" >> {{ log_file }}
        echo "7. REALVNC SERVER - $(date)" >> {{ log_file }}
        echo "===========================================================" >> {{ log_file }}
        echo "" >> {{ log_file }}

    # ==========================================================
    # 8. VISUAL STUDIO CODE
    # ==========================================================
    - name: Install Visual Studio Code
      block:
        - name: Create keyrings directory for VS Code
          file:
            path: /usr/share/keyrings
            state: directory
            mode: '0755'

        - name: Download Microsoft GPG key
          get_url:
            url: https://packages.microsoft.com/keys/microsoft.asc
            dest: /tmp/microsoft.asc
            mode: '0644'

        - name: Install Microsoft GPG key
          shell: gpg --dearmor < /tmp/microsoft.asc > /usr/share/keyrings/microsoft.gpg
          args:
            creates: /usr/share/keyrings/microsoft.gpg

        - name: Add VS Code repository
          apt_repository:
            repo: "deb [arch=amd64 signed-by=/usr/share/keyrings/microsoft.gpg] https://packages.microsoft.com/repos/vscode stable main"
            state: present
            filename: vscode
            update_cache: yes

        - name: Install VS Code package
          apt:
            name: code
            state: present

        - shell: echo "âœ… VS Code installed." >> {{ log_file }}
        - debug: msg="âœ… VS Code installed."
      rescue:
        - debug: msg="âš ï¸ VS Code repo or install failed."
        - shell: echo "âš ï¸ VS Code repo or install failed." >> {{ log_file }}
    
    - name: Log VS Code installation
      shell: |
        echo "===========================================================" >> {{ log_file }}
        echo "8. VISUAL STUDIO CODE - $(date)" >> {{ log_file }}
        echo "===========================================================" >> {{ log_file }}
        echo "" >> {{ log_file }}

    # ==========================================================
    # 9. DISPLAY SERVER (XORG) & VM DETECTION
    # ==========================================================
    - name: Detect if running in a virtual machine
      shell: systemd-detect-virt
      register: virt_detect
      failed_when: false
      changed_when: false

    - name: Set VM detection fact
      set_fact:
        is_virtual_machine: "{{ virt_detect.rc == 0 and virt_detect.stdout != 'none' }}"
        virtualization_type: "{{ virt_detect.stdout | default('none') }}"

    - name: Check if GDM3 is installed
      stat:
        path: /etc/gdm3/custom.conf
      register: gdm3_config

    - name: Check if LightDM is installed
      stat:
        path: /etc/lightdm/lightdm.conf
      register: lightdm_config

    - name: Disable Wayland and force Xorg (GDM3)
      lineinfile:
        path: /etc/gdm3/custom.conf
        regexp: '^#?WaylandEnable='
        line: 'WaylandEnable=false'
        insertafter: '^\[daemon\]'
        backup: yes
      notify: restart gdm3
      register: xorg_config_gdm3
      when: gdm3_config.stat.exists

    - name: Configure LightDM to use Xorg (if present)
      lineinfile:
        path: /etc/lightdm/lightdm.conf
        regexp: '^#?user-session='
        line: 'user-session=xubuntu'
        insertafter: '^\[Seat:\*\]'
        backup: yes
      notify: restart lightdm
      register: xorg_config_lightdm
      when: lightdm_config.stat.exists

    - name: Log display manager configuration
      shell: |
        {% if gdm3_config.stat.exists %}
        echo "âœ… GDM3 configured to use Xorg (Wayland disabled)" >> {{ log_file }}
        {% elif lightdm_config.stat.exists %}
        echo "âœ… LightDM configured to use Xorg" >> {{ log_file }}
        {% else %}
        echo "â„¹ï¸ No display manager (GDM3/LightDM) detected - skipping Wayland/Xorg configuration" >> {{ log_file }}
        {% endif %}

    - name: Apply VM-specific display fix (QXL)
      block:
        - name: Create X11 config directory
          file:
            path: /etc/X11/xorg.conf.d
            state: directory
            mode: '0755'

        - name: Configure QXL display for VMs
          copy:
            dest: /etc/X11/xorg.conf.d/10-qxl-display.conf
            mode: '0644'
            content: |
              Section "ServerFlags"
                  Option "AutoAddGPU" "false"
              EndSection

              Section "ServerLayout"
                  Identifier "Layout0"
                  Screen 0 "Screen0"
              EndSection

              Section "Device"
                  Identifier "QXL"
                  Driver "qxl"
                  BusID "PCI:0:1:0"
              EndSection

              Section "Screen"
                  Identifier "Screen0"
                  Device "QXL"
              EndSection
          notify:
            - restart gdm3
            - restart lightdm

        - name: Remove conflicting NVIDIA X11 config
          file:
            path: /etc/X11/xorg.conf.d/10-nvidia.conf
            state: absent
          notify:
            - restart gdm3
            - restart lightdm

        - shell: |
            echo "âœ… VM detected ({{ virtualization_type }}): Applied QXL display fix" >> {{ log_file }}

        - debug:
            msg: "âœ… VM detected ({{ virtualization_type }}): Applied QXL display fix"

      when: is_virtual_machine

    - name: Log display server configuration
      shell: |
        echo "===========================================================" >> {{ log_file }}
        echo "9. DISPLAY SERVER (XORG) & VM DETECTION - $(date)" >> {{ log_file }}
        echo "===========================================================" >> {{ log_file }}
        echo "System type: {{ 'Virtual Machine (' + virtualization_type + ')' if is_virtual_machine else 'Physical/Bare Metal' }}" >> {{ log_file }}
        echo "âœ… Display configured for Xorg (Wayland disabled)." >> {{ log_file }}
        echo "" >> {{ log_file }}

    - debug:
        msg: |
          âœ… Display configured for Xorg (Wayland disabled)
          System: {{ 'Virtual Machine (' + virtualization_type + ')' if is_virtual_machine else 'Physical/Bare Metal' }}

    # ==========================================================
    # 10. NVIDIA DRIVER & GRUB CONFIG (LOCAL REPO)
    # ==========================================================
    - name: Install NVIDIA driver from local repository
      block:
        - name: Download NVIDIA driver local repository package
          get_url:
            url: "{{ nvidia_driver_local_repo_url }}"
            dest: "{{ installers_base_path }}/nvidia-driver/nvidia-driver-local-repo.deb"
            mode: '0644'
            timeout: 300
          register: nvidia_driver_download

        - name: Calculate SHA-256 checksum of NVIDIA driver package
          shell: sha256sum {{ installers_base_path }}/nvidia-driver/nvidia-driver-local-repo.deb | awk '{print $1}'
          register: nvidia_driver_sha256
          changed_when: false
          when: nvidia_driver_download.changed

        - name: Log NVIDIA driver SHA-256 checksum
          shell: |
            echo "NVIDIA Driver SHA-256: {{ nvidia_driver_sha256.stdout }}" >> {{ log_file }}
            echo "  File: nvidia-driver-local-repo.deb" >> {{ log_file }}
            echo "  Downloaded: {{ ansible_date_time.iso8601 }}" >> {{ log_file }}
            echo "{{ nvidia_driver_sha256.stdout }}  nvidia-driver/nvidia-driver-local-repo.deb" >> {{ installers_base_path }}/SHA256SUMS
          when: nvidia_driver_download.changed

        - name: Install NVIDIA driver local repository package
          apt:
            deb: "{{ installers_base_path }}/nvidia-driver/nvidia-driver-local-repo.deb"
            state: present

        - name: Find NVIDIA driver repository directory
          shell: find /var -maxdepth 1 -type d -name 'nvidia-driver-local-repo-*' | head -n 1
          register: nvidia_repo_dir
          changed_when: false

        - name: Copy NVIDIA driver GPG key to keyrings
          shell: cp {{ nvidia_repo_dir.stdout }}/nvidia-*-keyring.gpg /usr/share/keyrings/
          args:
            creates: /usr/share/keyrings/nvidia-*-keyring.gpg
          when: nvidia_repo_dir.stdout != ""

        - name: Update apt cache with NVIDIA driver repository
          apt:
            update_cache: yes

        - name: Install NVIDIA driver meta-package
          apt:
            name: "nvidia-driver-{{ nvidia_driver_version }}"
            state: present
            update_cache: yes
          register: nvidia_driver_install

        - name: Configure GRUB for NVIDIA KMS
          lineinfile:
            path: /etc/default/grub
            regexp: '^GRUB_CMDLINE_LINUX_DEFAULT='
            line: 'GRUB_CMDLINE_LINUX_DEFAULT="quiet splash nvidia-drm.modeset=1"'
            backup: yes
          register: grub_updated

        - name: Update GRUB configuration
          command: update-grub
          when: grub_updated.changed

        - name: Configure NVIDIA modprobe options
          copy:
            dest: /etc/modprobe.d/nvidia.conf
            mode: '0644'
            content: |
              options nvidia-drm modeset=1
              options nvidia NVreg_PreserveVideoMemoryAllocations=1

        - shell: echo "âœ… NVIDIA driver {{ nvidia_driver_version_full }} installed from local repository." >> {{ log_file }}

    - name: Log NVIDIA driver installation
      shell: |
        echo "===========================================================" >> {{ log_file }}
        echo "10. NVIDIA DRIVER & GRUB CONFIG - $(date)" >> {{ log_file }}
        echo "===========================================================" >> {{ log_file }}
        echo "Installed NVIDIA driver {{ nvidia_driver_version_full }} from local repository" >> {{ log_file }}
        echo "Stored in: {{ installers_base_path }}/nvidia-driver/" >> {{ log_file }}
        echo "" >> {{ log_file }}

    - debug: msg="âœ… NVIDIA driver {{ nvidia_driver_version_full }} installed from local repository."

    # Hold NVIDIA driver packages to prevent upgrades
    - name: Get list of installed NVIDIA driver packages
      shell: dpkg -l | grep '^ii' | grep -E 'nvidia.*-{{ nvidia_driver_version }}' | awk '{print $2}'
      register: nvidia_packages_list
      changed_when: false
      failed_when: false

    - name: Hold NVIDIA driver packages
      dpkg_selections:
        name: "{{ item }}"
        selection: hold
      loop: "{{ nvidia_packages_list.stdout_lines }}"
      when: nvidia_packages_list.stdout_lines | length > 0

    - name: Verify NVIDIA driver packages are held
      shell: dpkg --get-selections | grep -E 'nvidia.*-{{ nvidia_driver_version }}' | grep hold
      register: nvidia_held_packages
      changed_when: false
      failed_when: nvidia_held_packages.rc != 0

    - name: Log NVIDIA driver version locking
      shell: |
        echo "ðŸ”’ Version Locking: {{ nvidia_held_packages.stdout_lines | length }} NVIDIA driver packages held" >> {{ log_file }}
        echo "Packages will NOT upgrade with 'apt upgrade'" >> {{ log_file }}
        echo "" >> {{ log_file }}

    - debug:
        msg: "ðŸ”’ {{ nvidia_held_packages.stdout_lines | length }} NVIDIA driver packages held to prevent upgrades"

    # ==========================================================
    # 11. CUDA TOOLKIT (LOCAL REPO)
    # ==========================================================
    - name: Install CUDA Toolkit from local repository
      block:
        - name: Download CUDA local repository package
          get_url:
            url: "{{ cuda_local_repo_url }}"
            dest: "{{ installers_base_path }}/cuda/cuda-repo-local.deb"
            mode: '0644'
            timeout: 600
          register: cuda_download

        - name: Calculate SHA-256 checksum of CUDA package
          shell: sha256sum {{ installers_base_path }}/cuda/cuda-repo-local.deb | awk '{print $1}'
          register: cuda_sha256
          changed_when: false
          when: cuda_download.changed

        - name: Log CUDA SHA-256 checksum
          shell: |
            echo "CUDA Toolkit SHA-256: {{ cuda_sha256.stdout }}" >> {{ log_file }}
            echo "  File: cuda-repo-local.deb" >> {{ log_file }}
            echo "  Downloaded: {{ ansible_date_time.iso8601 }}" >> {{ log_file }}
            echo "{{ cuda_sha256.stdout }}  cuda/cuda-repo-local.deb" >> {{ installers_base_path }}/SHA256SUMS
          when: cuda_download.changed

        - name: Install CUDA local repository package
          apt:
            deb: "{{ installers_base_path }}/cuda/cuda-repo-local.deb"
            state: present

        - name: Find CUDA repository directory
          shell: find /var -maxdepth 1 -type d -name 'cuda-repo-ubuntu2404-*-local' | head -n 1
          register: cuda_repo_dir
          changed_when: false

        - name: Copy CUDA GPG key to keyrings
          shell: cp {{ cuda_repo_dir.stdout }}/cuda-*-keyring.gpg /usr/share/keyrings/
          args:
            creates: /usr/share/keyrings/cuda-*-keyring.gpg
          when: cuda_repo_dir.stdout != ""

        - name: Update apt cache with CUDA repository
          apt:
            update_cache: yes

        - name: Install CUDA toolkit package
          apt:
            name: "cuda-toolkit-{{ cuda_version }}"
            state: present
            update_cache: yes

        - name: Configure CUDA environment in /etc/profile.d/
          copy:
            dest: /etc/profile.d/cuda.sh
            mode: '0644'
            content: |
              export PATH=/usr/local/cuda-{{ cuda_version_full }}/bin:$PATH
              export LD_LIBRARY_PATH=/usr/local/cuda-{{ cuda_version_full }}/lib64:$LD_LIBRARY_PATH

        - name: Configure CUDA library path for ldconfig
          copy:
            dest: /etc/ld.so.conf.d/cuda.conf
            mode: '0644'
            content: |
              /usr/local/cuda-{{ cuda_version_full }}/lib64
          notify: update ldconfig

        - shell: echo "âœ… CUDA {{ cuda_version_full }} installed from local repository." >> {{ log_file }}
        - debug: msg="âœ… CUDA {{ cuda_version_full }} installed from local repository."
      rescue:
        - debug: msg="âš ï¸ CUDA installation failed."
        - shell: echo "âš ï¸ CUDA installation failed." >> {{ log_file }}

    - name: Log CUDA installation
      shell: |
        echo "===========================================================" >> {{ log_file }}
        echo "11. CUDA TOOLKIT - $(date)" >> {{ log_file }}
        echo "===========================================================" >> {{ log_file }}
        echo "Installed CUDA {{ cuda_version_full }} from local repository" >> {{ log_file }}
        echo "Stored in: {{ installers_base_path }}/cuda/" >> {{ log_file }}
        echo "" >> {{ log_file }}

    # Hold CUDA packages to prevent upgrades
    - name: Hold CUDA packages to prevent upgrades
      dpkg_selections:
        name: "{{ item }}"
        selection: hold
      loop:
        - "cuda-toolkit-{{ cuda_version }}"
        - "cuda-runtime-{{ cuda_version }}"
        - "cuda-libraries-{{ cuda_version }}"
        - "cuda-libraries-dev-{{ cuda_version }}"
        - "cuda-nvcc-{{ cuda_version }}"
        - "cuda-cudart-{{ cuda_version }}"
        - "cuda-cudart-dev-{{ cuda_version }}"

    - name: Get list of all installed CUDA packages for holding
      shell: dpkg -l | grep '^ii' | grep -E 'cuda-|libcu' | grep '{{ cuda_version }}' | awk '{print $2}'
      register: additional_cuda_packages
      changed_when: false
      failed_when: false

    - name: Hold additional CUDA packages
      dpkg_selections:
        name: "{{ item }}"
        selection: hold
      loop: "{{ additional_cuda_packages.stdout_lines }}"
      when: additional_cuda_packages.stdout_lines | length > 0

    - name: Verify CUDA packages are held
      shell: dpkg --get-selections | grep -E 'cuda-|libcu' | grep '{{ cuda_version }}' | grep hold
      register: cuda_held_packages
      changed_when: false
      failed_when: cuda_held_packages.rc != 0

    - name: Log CUDA version locking
      shell: |
        echo "ðŸ”’ Version Locking: {{ cuda_held_packages.stdout_lines | length }} CUDA packages held" >> {{ log_file }}
        echo "Packages will NOT upgrade with 'apt upgrade'" >> {{ log_file }}
        echo "" >> {{ log_file }}

    - debug:
        msg: "ðŸ”’ {{ cuda_held_packages.stdout_lines | length }} CUDA packages held to prevent upgrades"

    # ==========================================================
    # 12. TENSORRT
    # ==========================================================
    - name: Install TensorRT with version pinning
      block:
        # Detect Ubuntu version and architecture
        - name: Get Ubuntu codename
          shell: . /etc/os-release && echo "$VERSION_CODENAME"
          register: ubuntu_codename
          changed_when: false

        - name: Get system architecture
          command: dpkg --print-architecture
          register: system_arch
          changed_when: false

        - name: Construct TensorRT local repo URL automatically
          set_fact:
            tensorrt_auto_url: "https://developer.download.nvidia.com/compute/tensorrt/{{ tensorrt_version_full }}/local_installers/nv-tensorrt-local-repo-ubuntu{{ ansible_distribution_version | replace('.', '') }}-{{ tensorrt_version_full }}-cuda-{{ cuda_version_full }}_1.0-1_{{ system_arch.stdout }}.deb"

        - name: Set final TensorRT URL
          set_fact:
            tensorrt_final_url: "{{ tensorrt_local_repo_url if tensorrt_local_repo_url != '' else tensorrt_auto_url }}"

        - name: Display TensorRT installation plan
          debug:
            msg: |
              TensorRT Installation Configuration:
              - Method: {{ tensorrt_install_method }}
              - Version: {{ tensorrt_version_full }}
              - CUDA: {{ cuda_version_full }}
              - Ubuntu: {{ ubuntu_codename.stdout }}
              - Architecture: {{ system_arch.stdout }}
              {% if tensorrt_install_method == 'local' %}
              - Local repo URL: {{ tensorrt_final_url }}
              {% endif %}

        # Method 1: Local Repository
        - name: Install TensorRT from local repository
          when: tensorrt_install_method == 'local' or tensorrt_install_method == 'auto'
          block:
            - name: Download TensorRT local repo package
              get_url:
                url: "{{ tensorrt_final_url }}"
                dest: /tmp/tensorrt-local-repo.deb
                timeout: 300
              register: tensorrt_download
              failed_when: false

            - name: Install TensorRT local repo package
              apt:
                deb: /tmp/tensorrt-local-repo.deb
              when: tensorrt_download is succeeded

            - name: Copy TensorRT repo keyring
              shell: cp /var/nv-tensorrt-local-repo-*/tensorrt-*-keyring.gpg /usr/share/keyrings/ 2>/dev/null || cp /var/nv-tensorrt-local-repo-*/*-keyring.gpg /usr/share/keyrings/
              when: tensorrt_download is succeeded
              register: keyring_copy
              failed_when: false

            - name: Update apt cache for TensorRT local repo
              apt:
                update_cache: yes
              when: tensorrt_download is succeeded

            - name: Install TensorRT from local repo
              apt:
                name:
                  - tensorrt-dev
                  - tensorrt-libs
                  - python3-libnvinfer
                  - python3-libnvinfer-dev
                state: present
              when: tensorrt_download is succeeded
              register: trt_local_install

        # Method 2: Network Repository (when local fails or method is "network")
        - name: Install TensorRT from network repository
          when: (tensorrt_install_method == 'network') or (tensorrt_install_method == 'auto' and (tensorrt_download is failed or trt_local_install is failed))
          block:
            - name: Update apt cache for TensorRT
              apt:
                update_cache: yes

            - name: Check available TensorRT versions in network repo
              shell: apt-cache madison tensorrt-dev | grep "{{ tensorrt_version_pattern }}" | head -1 | awk '{print $3}'
              register: available_trt_version
              failed_when: false
              changed_when: false

            - name: Fail if requested TensorRT version not available
              fail:
                msg: |
                  TensorRT {{ tensorrt_version_pattern }} not found in network repository!

                  When newer TensorRT versions are released, NVIDIA removes old versions from the network repo.

                  SOLUTION: Set tensorrt_install_method to "local" or "auto" to use local repository.
                  The playbook will automatically construct the correct URL:
                  {{ tensorrt_final_url }}

                  Or download manually from: https://developer.nvidia.com/tensorrt
              when: available_trt_version.stdout == ''

            - name: Set TensorRT package version from network repo
              set_fact:
                trt_pkg_version: "{{ available_trt_version.stdout }}"

            - name: Install TensorRT packages with specific version from network repo
              apt:
                name:
                  - "tensorrt-dev={{ trt_pkg_version }}"
                  - "tensorrt-libs={{ trt_pkg_version }}"
                  - "libnvinfer10={{ trt_pkg_version }}"
                  - "libnvinfer-dev={{ trt_pkg_version }}"
                  - "libnvinfer-headers-dev={{ trt_pkg_version }}"
                  - "libnvinfer-plugin10={{ trt_pkg_version }}"
                  - "libnvonnxparsers10={{ trt_pkg_version }}"
                  - "python3-libnvinfer={{ trt_pkg_version }}"
                  - "python3-libnvinfer-dev={{ trt_pkg_version }}"
                state: present
                allow_downgrades: yes
              register: trt_install

        - name: Hold TensorRT packages to prevent upgrades
          dpkg_selections:
            name: "{{ item }}"
            selection: hold
          loop:
            - tensorrt-dev
            - tensorrt-libs
            - libnvinfer10
            - libnvinfer-dev
            - libnvinfer-headers-dev
            - libnvinfer-plugin10
            - libnvonnxparsers10
            - python3-libnvinfer
            - python3-libnvinfer-dev

        - name: Verify packages are held
          shell: dpkg --get-selections | grep -E "(tensorrt|libnvinfer)" | grep hold
          register: held_packages
          changed_when: false
          failed_when: held_packages.rc != 0

        - name: Verify installed TensorRT version
          shell: dpkg -l | grep -E "(tensorrt|libnvinfer)" | grep -v "^rc"
          register: trt_ver
          changed_when: false

        - shell: |
            echo "{{ trt_ver.stdout }}" >> {{ log_file }}
            echo "" >> {{ log_file }}
            echo "Packages held (will NOT be upgraded by apt):" >> {{ log_file }}
            echo "{{ held_packages.stdout }}" >> {{ log_file }}

        - name: Determine which method was used
          set_fact:
            trt_method_used: "{{ 'Local Repository' if (tensorrt_download is defined and tensorrt_download is succeeded) else 'Network Repository' }}"

        - debug:
            msg: |
              âœ… TensorRT {{ tensorrt_version_full }} installed and pinned
              Installation method: {{ trt_method_used }}
              {% if trt_method_used == 'Local Repository' %}
              Local repo URL: {{ tensorrt_final_url }}
              {% endif %}

              Held packages (protected from apt upgrade):
              {{ held_packages.stdout_lines }}

    - name: Log TensorRT installation
      shell: |
        echo "===========================================================" >> {{ log_file }}
        echo "12. TENSORRT - $(date)" >> {{ log_file }}
        echo "===========================================================" >> {{ log_file }}
        echo "" >> {{ log_file }}

    # ==========================================================
    # 13. UNATTENDED-UPGRADES PROTECTION
    # ==========================================================
    - name: Create unattended-upgrades GPU stack blacklist
      copy:
        dest: /etc/apt/apt.conf.d/51nvidia-blacklist
        mode: '0644'
        content: |
          // Prevent automatic upgrades of GPU stack packages
          // This ensures the frozen NVIDIA driver + CUDA + TensorRT versions remain stable
          Unattended-Upgrade::Package-Blacklist {
              "nvidia-driver-*";
              "nvidia-utils-*";
              "libnvidia-*";
              "nvidia-kernel-*";
              "nvidia-dkms-*";
              "cuda-*";
              "libcu*";
              "tensorrt-*";
              "libnvinfer*";
              "libnvonnxparsers*";
          };

    - name: Log unattended-upgrades protection
      shell: |
        echo "===========================================================" >> {{ log_file }}
        echo "13. UNATTENDED-UPGRADES PROTECTION - $(date)" >> {{ log_file }}
        echo "===========================================================" >> {{ log_file }}
        echo "Created GPU stack blacklist in /etc/apt/apt.conf.d/51nvidia-blacklist" >> {{ log_file }}
        echo "GPU packages will NOT be automatically upgraded" >> {{ log_file }}
        echo "" >> {{ log_file }}

    - debug:
        msg: "ðŸ›¡ï¸ Unattended-upgrades GPU stack blacklist created"

    # ==========================================================
    # 14. APT PREFERENCES (PIN-PRIORITY 1001)
    # ==========================================================
    - name: Create APT preferences for GPU stack pinning
      copy:
        dest: /etc/apt/preferences.d/99-gpu-stack-pinning
        mode: '0644'
        content: |
          # Pin NVIDIA Driver {{ nvidia_driver_version_full }} - Highest Priority
          Package: nvidia-driver-{{ nvidia_driver_version }}
          Pin: version {{ nvidia_driver_version_full }}*
          Pin-Priority: 1001

          Package: nvidia-*-{{ nvidia_driver_version }}
          Pin: version *
          Pin-Priority: 1001

          # Pin CUDA Toolkit {{ cuda_version_full }}
          Package: cuda-toolkit-{{ cuda_version }}
          Pin: version *
          Pin-Priority: 1001

          Package: cuda-*-{{ cuda_version }}
          Pin: version *
          Pin-Priority: 1001

          Package: libcu*
          Pin: version *{{ cuda_version_full }}*
          Pin-Priority: 1001

          # Pin TensorRT {{ tensorrt_version_full }}
          Package: tensorrt-*
          Pin: version *{{ tensorrt_version_full }}*
          Pin-Priority: 1001

          Package: libnvinfer*
          Pin: version *
          Pin-Priority: 1001

          # Prevent newer CUDA versions from being installed
          Package: cuda-toolkit-14-*
          Pin: version *
          Pin-Priority: -1

          Package: cuda-toolkit-15-*
          Pin: version *
          Pin-Priority: -1

    - name: Log APT preferences creation
      shell: |
        echo "===========================================================" >> {{ log_file }}
        echo "14. APT PREFERENCES PINNING - {{ ansible_date_time.iso8601 }}" >> {{ log_file }}
        echo "===========================================================" >> {{ log_file }}
        echo "Created /etc/apt/preferences.d/99-gpu-stack-pinning" >> {{ log_file }}
        echo "Pin-Priority 1001 for nvidia-{{ nvidia_driver_version }}, cuda-{{ cuda_version }}, tensorrt-{{ tensorrt_version_full }}" >> {{ log_file }}
        echo "Fourth layer of protection (beyond dpkg hold + unattended-upgrades)" >> {{ log_file }}
        echo "" >> {{ log_file }}

    - debug:
        msg: "ðŸ“Œ APT preferences pinning created (Pin-Priority 1001)"

    # ==========================================================
    # 15. REPOSITORY CLEANUP
    # ==========================================================
    - name: Clean up old local repositories
      shell: |
        # Keep only the most recent TensorRT local repo
        find /var -maxdepth 1 -mindepth 1 -type d -name 'nv-tensorrt-local-repo-*' 2>/dev/null | sort -r | tail -n +2 | xargs -r rm -rf 2>/dev/null || true
        # Keep only the most recent CUDA local repo
        find /var -maxdepth 1 -mindepth 1 -type d -name 'cuda-repo-ubuntu2404-*-local' 2>/dev/null | sort -r | tail -n +2 | xargs -r rm -rf 2>/dev/null || true
        # Keep only the most recent NVIDIA driver local repo
        find /var -maxdepth 1 -mindepth 1 -type d -name 'nvidia-driver-local-repo-*' 2>/dev/null | sort -r | tail -n +2 | xargs -r rm -rf 2>/dev/null || true
      failed_when: false
      changed_when: false

    - name: Log repository cleanup
      shell: |
        echo "===========================================================" >> {{ log_file }}
        echo "15. REPOSITORY CLEANUP - {{ ansible_date_time.iso8601 }}" >> {{ log_file }}
        echo "===========================================================" >> {{ log_file }}
        echo "Cleaned up old local repositories (kept most recent only)" >> {{ log_file }}
        echo "" >> {{ log_file }}

    - debug:
        msg: "ðŸ§¹ Old local repositories cleaned up"

    # ==========================================================
    # 15. DOCKER + NVIDIA RUNTIME
    # ==========================================================
    - name: Install Docker and NVIDIA container runtime
      block:
        - name: Install Docker prerequisites
          apt:
            name:
              - apt-transport-https
              - ca-certificates
              - curl
              - gnupg
              - lsb-release
            state: present

        - name: Create keyrings directory
          file:
            path: /etc/apt/keyrings
            state: directory
            mode: '0755'

        - name: Download Docker GPG key directly to keyrings
          shell: curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc
          args:
            creates: /etc/apt/keyrings/docker.asc

        - name: Set permissions on Docker GPG key
          file:
            path: /etc/apt/keyrings/docker.asc
            mode: '0644'

        - name: Add Docker repository with dynamic architecture and codename
          shell: |
            echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \
            $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | \
            tee /etc/apt/sources.list.d/docker.list > /dev/null
          args:
            creates: /etc/apt/sources.list.d/docker.list

        - name: Update apt cache for Docker
          apt:
            update_cache: yes

        - name: Install Docker packages
          apt:
            name:
              - docker-ce
              - docker-ce-cli
              - containerd.io
              - docker-buildx-plugin
              - docker-compose-plugin
            state: present

        - name: Add user to docker group
          user:
            name: "{{ ssh_user }}"
            groups: docker
            append: yes

        - name: Create keyrings directory for NVIDIA Container Toolkit
          file:
            path: /usr/share/keyrings
            state: directory
            mode: '0755'

        - name: Download and install NVIDIA Container Toolkit GPG key
          shell: |
            curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | \
            gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
          args:
            creates: /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg

        - name: Add NVIDIA Container Toolkit repository
          shell: |
            curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
            sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
            tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
          args:
            creates: /etc/apt/sources.list.d/nvidia-container-toolkit.list

        - name: Update apt cache for NVIDIA Container Toolkit
          apt:
            update_cache: yes

        - name: Install NVIDIA Container Toolkit
          apt:
            name: nvidia-container-toolkit
            state: present

        - name: Configure Docker runtime using nvidia-ctk
          command: nvidia-ctk runtime configure --runtime=docker
          register: nvidia_ctk_config
          changed_when: nvidia_ctk_config.rc == 0
          notify: restart docker

        - name: Start and enable Docker service
          systemd:
            name: docker
            state: started
            enabled: yes

        - shell: echo "âœ… Docker and NVIDIA Container Toolkit installed." >> {{ log_file }}
        - debug: msg="âœ… Docker and NVIDIA Container Toolkit installed."
      rescue:
        - debug: msg="âš ï¸ Docker installation failed."
        - shell: echo "âš ï¸ Docker installation failed." >> {{ log_file }}
    
    - name: Log Docker installation
      shell: |
        echo "===========================================================" >> {{ log_file }}
        echo "13. DOCKER + NVIDIA RUNTIME - $(date)" >> {{ log_file }}
        echo "===========================================================" >> {{ log_file }}
        echo "" >> {{ log_file }}

    # ==========================================================
    # 14. PYTHON & DEV TOOLS
    # ==========================================================
    - name: Install Python and dev tools
      apt:
        name:
          - python3
          - python3-pip
          - python3-venv
          - python3.12-venv
          - python3-dev
        state: present
      register: python_install
    
    - shell: python3 --version
      register: pyver
    
    - name: Log Python installation
      shell: |
        echo "===========================================================" >> {{ log_file }}
        echo "14. PYTHON & DEV TOOLS - $(date)" >> {{ log_file }}
        echo "===========================================================" >> {{ log_file }}
        echo "âœ… Python {{ pyver.stdout }} installed." >> {{ log_file }}
        echo "" >> {{ log_file }}
    
    - debug: msg="âœ… Python {{ pyver.stdout }} installed."

    # ==========================================================
    # 15. HEALTHCHECKS.IO SERVICE
    # ==========================================================
    - name: Setup Healthchecks.io service
      block:
        - name: Create healthcheck ping script
          copy:
            dest: /usr/local/bin/healthcheck-ping.sh
            mode: '0755'
            content: |
              #!/bin/bash
              set -e
              curl -fsS -m 10 --retry 5 -o /dev/null "{{ healthchecks_url }}" || echo "Healthcheck failed $(date)"
        - name: Create systemd service for healthcheck
          copy:
            dest: /etc/systemd/system/healthcheck.service
            mode: '0644'
            content: |
              [Unit]
              Description=Healthchecks.io ping

              [Service]
              Type=oneshot
              ExecStart=/usr/local/bin/healthcheck-ping.sh
        - name: Create systemd timer for healthcheck (every 5 minutes)
          copy:
            dest: /etc/systemd/system/healthcheck.timer
            mode: '0644'
            content: |
              [Unit]
              Description=Run healthcheck ping every 5 minutes

              [Timer]
              OnBootSec=1min
              OnUnitActiveSec=5min
              AccuracySec=30s

              [Install]
              WantedBy=timers.target
          notify: reload systemd
        - name: Enable and start healthcheck timer
          systemd: { name: healthcheck.timer, enabled: yes, state: started }
          register: healthcheck_timer

        - name: Log healthcheck configuration
          shell: |
            echo "===========================================================" >> {{ log_file }}
            echo "15. HEALTHCHECKS.IO SERVICE - $(date)" >> {{ log_file }}
            echo "===========================================================" >> {{ log_file }}
            echo "âœ… Healthcheck service active (ping every 5 min)." >> {{ log_file }}
            echo "URL: {{ healthchecks_url }}" >> {{ log_file }}
            echo "" >> {{ log_file }}

        - debug: msg="âœ… Healthcheck service active (ping every 5 min) - {{ healthchecks_url }}"
      when: healthchecks_url != 'SKIPPED'

    - name: Log healthcheck skipped
      block:
        - shell: |
            echo "===========================================================" >> {{ log_file }}
            echo "15. HEALTHCHECKS.IO SERVICE - $(date)" >> {{ log_file }}
            echo "===========================================================" >> {{ log_file }}
            echo "âš ï¸  Healthcheck service skipped (no URL provided)." >> {{ log_file }}
            echo "" >> {{ log_file }}

        - debug: msg="âš ï¸  Healthcheck service skipped (no URL provided)."
      when: healthchecks_url == 'SKIPPED'

    # ==========================================================
    # 16. AUTO_TEST PYTHON ENVIRONMENT SETUP
    # ==========================================================
    - name: Create code directory structure
      file:
        path: "{{ user_home }}/code/auto_test"
        state: directory
        mode: '0755'
        owner: "{{ ssh_user }}"
        group: "{{ ssh_user }}"

    - name: Create Python 3.12 virtual environment
      become: yes
      become_user: "{{ ssh_user }}"
      command: python3.12 -m venv "{{ user_home }}/code/auto_test/venv"
      args:
        creates: "{{ user_home }}/code/auto_test/venv"

    - name: Upgrade pip, setuptools, and wheel in venv
      become: yes
      become_user: "{{ ssh_user }}"
      shell: |
        source {{ user_home }}/code/auto_test/venv/bin/activate
        pip install --upgrade pip setuptools wheel
      args:
        executable: /bin/bash

    - name: Create activation helper script
      copy:
        dest: "{{ user_home }}/code/auto_test/activate.sh"
        mode: '0755'
        owner: "{{ ssh_user }}"
        group: "{{ ssh_user }}"
        content: |
          #!/bin/bash
          source {{ user_home }}/code/auto_test/venv/bin/activate
          echo "Virtual environment activated!"
          echo "Python: $(which python3)"
          python3 << 'EOF'
          import torch
          print(f"PyTorch {torch.__version__} - CUDA available: {torch.cuda.is_available()}")
          if torch.cuda.is_available():
              print(f"GPU: {torch.cuda.get_device_name(0)}")
          EOF

    - name: Log auto_test environment setup
      shell: |
        echo "===========================================================" >> {{ log_file }}
        echo "16. AUTO_TEST PYTHON ENVIRONMENT SETUP - $(date)" >> {{ log_file }}
        echo "===========================================================" >> {{ log_file }}
        echo "âœ… Created ~/code/auto_test directory" >> {{ log_file }}
        echo "âœ… Python 3.12 virtual environment created" >> {{ log_file }}
        echo "" >> {{ log_file }}
        echo "âš ï¸  ML packages (PyTorch, ultralytics, etc.) will be installed after reboot" >> {{ log_file }}
        echo "âš ï¸  Run post-reboot-verify.yml after reboot to install and verify" >> {{ log_file }}
        echo "" >> {{ log_file }}

    - debug:
        msg: |
          âœ… Virtual environment created at ~/code/auto_test

          âš ï¸  Reboot required to load NVIDIA driver
          âš ï¸  After reboot, run: ansible-playbook post-reboot-verify.yml -K
          This will install PyTorch, ultralytics, TensorRT, and verify CUDA

    # ==========================================================
    # 17. REBOOT NOTIFICATION
    # ==========================================================
    - name: Check if reboot is required
      stat:
        path: /var/run/reboot-required
      register: reboot_required_file

    - name: Set reboot requirement fact
      set_fact:
        needs_reboot: "{{ reboot_required_file.stat.exists or nvidia_driver_install.changed }}"

    - name: Log reboot requirement
      shell: |
        echo "===========================================================" >> {{ log_file }}
        echo "17. REBOOT NOTIFICATION - $(date)" >> {{ log_file }}
        echo "===========================================================" >> {{ log_file }}
        {% if needs_reboot %}
        echo "âš ï¸  REBOOT REQUIRED" >> {{ log_file }}
        echo "NVIDIA driver and/or kernel modules have been updated." >> {{ log_file }}
        echo "Please reboot to activate all changes: sudo reboot" >> {{ log_file }}
        {% else %}
        echo "âœ… No reboot required at this time." >> {{ log_file }}
        {% endif %}
        echo "" >> {{ log_file }}

    - name: Display reboot notification
      debug:
        msg: |
          âš ï¸  ============================================
          âš ï¸  REBOOT REQUIRED
          âš ï¸  ============================================
          NVIDIA driver and/or kernel modules have been updated.
          The system needs to be rebooted to activate all changes.

          Please reboot when convenient:
            sudo reboot
      when: needs_reboot

    # ==========================================================
    # 18. FINAL MESSAGE
    # ==========================================================
    - name: Write final summary to log
      shell: |
        echo "===================================================================" >> {{ log_file }}
        echo "âœ… Setup complete!" >> {{ log_file }}
        echo "- NVIDIA driver {{ nvidia_driver_version }}, CUDA {{ cuda_version_full }}" >> {{ log_file }}
        echo "- TensorRT installed" >> {{ log_file }}
        echo "- SSH on port {{ ssh_port }} (key-only)" >> {{ log_file }}
        echo "- Docker + NVIDIA runtime ready" >> {{ log_file }}
        echo "- Tailscale and RealVNC installed" >> {{ log_file }}
        {% if healthchecks_url != 'SKIPPED' %}
        echo "- Healthcheck active (every 5 min): {{ healthchecks_url }}" >> {{ log_file }}
        {% else %}
        echo "- Healthcheck skipped (no URL provided)" >> {{ log_file }}
        {% endif %}
        echo "- Auto reboot daily at {{ auto_reboot_time }}" >> {{ log_file }}
        echo "- Auto test environment: ~/code/auto_test (Python 3.12 venv)" >> {{ log_file }}
        echo "===================================================================" >> {{ log_file }}
        echo "Completed at: $(date)" >> {{ log_file }}
        echo "Log file: {{ log_file }}" >> {{ log_file }}
        {% if needs_reboot %}
        echo "" >> {{ log_file }}
        echo "âš ï¸  Please reboot the system: sudo reboot" >> {{ log_file }}
        {% endif %}

    - debug:
        msg: |
          ===================================================================
          âœ… Setup complete!
          - NVIDIA driver {{ nvidia_driver_version }}, CUDA {{ cuda_version_full }}
          - TensorRT installed
          - SSH on port {{ ssh_port }} (key-only)
          - Docker + NVIDIA runtime ready
          - Tailscale and RealVNC installed
          {% if healthchecks_url != 'SKIPPED' %}
          - Healthcheck active (every 5 min): {{ healthchecks_url }}
          {% else %}
          - Healthcheck skipped (no URL provided)
          {% endif %}
          - Auto reboot daily at {{ auto_reboot_time }}
          - Auto test environment: ~/code/auto_test (Python 3.12 venv)

          Activate venv: source ~/code/auto_test/activate.sh
          Log file saved to: {{ log_file }}
          {% if needs_reboot %}

          âš ï¸  Please reboot the system: sudo reboot
          {% endif %}
          ===================================================================

  handlers:
    - name: restart sshd
      systemd: { name: sshd, state: restarted }
    - name: restart docker
      systemd: { name: docker, state: restarted }
    - name: restart gdm3
      systemd: { name: gdm3, state: restarted }
      when: gdm3_config.stat.exists | default(false)
    - name: restart lightdm
      systemd: { name: lightdm, state: restarted }
      when: lightdm_config.stat.exists | default(false)
    - name: update ldconfig
      command: ldconfig
    - name: reload systemd
      systemd: { daemon_reload: yes }
